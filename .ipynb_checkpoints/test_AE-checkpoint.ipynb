{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from ordereddict import OrderedDict\n",
    "os.environ['THEANO_FLAGS']=\"device=cpu\"\n",
    "\n",
    "from utils import tile_raster_images\n",
    "from pylearn2.utils import serial\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "try:\n",
    "    import PIL.Image as Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "import IPython.display as I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIR_DATA = '/Users/vmisra/data/AE_experiments'\n",
    "dir_model = os.path.join(DIR_DATA,'models')\n",
    "dir_fuel = os.path.join(DIR_DATA,'fuel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load models and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = serial.load(os.path.join(dir_fuel,'mnist_test_X.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_folders = [model_folder \\\n",
    "               for model_folder in os.listdir(dir_model) \\\n",
    "               if os.path.isdir(os.path.join(dir_model,model_folder))]\n",
    "model_folders = ['B16','B17','B18','B19','B20']\n",
    "submodels = ['0.pkl','1.pkl','2.pkl','3.pkl']\n",
    "final_model='finetune.pkl'\n",
    "submodel_set = submodels+[final_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outputs(models, submodels=None, finetuned=None):\n",
    "    xhat = OrderedDict()\n",
    "    if submodels != None:\n",
    "        for (idx,submodel) in enumerate(submodels):\n",
    "            X = models[submodel].get_input_space().make_theano_batch()\n",
    "            Y = X\n",
    "            for jdx in range(idx+1):\n",
    "                Y = models[submodels[jdx]].encode(Y)\n",
    "            for jdx in range(idx+1)[::-1]:\n",
    "                Y = models[submodel[jdx]].decode(Y)\n",
    "            xhat[submodel] = Y.eval({X:test_data})\n",
    "    if finetuned != None:\n",
    "        X = models[finetuned].get_input_space().make_theano_batch()\n",
    "        Y = models[finetuned].reconstruct(X)\n",
    "        xhat[finetuned] = Y.eval({X:test_data})\n",
    "    return xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 650M\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: x has 784 cols (and 10000 rows) but y has 1000 rows (and 5 cols)\nApply node that caused the error: Dot22(<TensorType(float32, matrix)>, HostFromGpu.0)\nToposort index: 4\nInputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]\nInputs shapes: [(10000, 784), (1000, 5)]\nInputs strides: [(3136, 4), (20, 4)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Elemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 1)](InplaceDimShuffle{x,0}.0, Dot22.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9021b8216c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mxhats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinetuned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-811acede7002>\u001b[0m in \u001b[0;36mget_outputs\u001b[0;34m(models, submodels, finetuned)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mjdx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mxhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinetuned\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinetuned\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_theano_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vmisra/anaconda/lib/python2.7/site-packages/theano/gof/graph.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, inputs_to_values)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vmisra/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                         storage_map=self.fn.storage_map)\n\u001b[0m\u001b[1;32m    611\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0;31m# For the c linker We don't have access from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vmisra/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: x has 784 cols (and 10000 rows) but y has 1000 rows (and 5 cols)\nApply node that caused the error: Dot22(<TensorType(float32, matrix)>, HostFromGpu.0)\nToposort index: 4\nInputs types: [TensorType(float32, matrix), TensorType(float32, matrix)]\nInputs shapes: [(10000, 784), (1000, 5)]\nInputs strides: [(3136, 4), (20, 4)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Elemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 1)](InplaceDimShuffle{x,0}.0, Dot22.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "xhats = OrderedDict()\n",
    "for model_folder in model_folders:\n",
    "    models = OrderedDict()\n",
    "    for submodel in submodel_set:\n",
    "        path = os.path.join(dir_model,model_folder,submodel)\n",
    "        if os.path.exists(path):\n",
    "            models[submodel] = serial.load(path)\n",
    "    xhats[model_folder] = get_outputs(models=models, submodels=submodels, finetuned=final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "('Error allocating 368640 bytes of device memory (out of memory).', <function CudaNdarray_unpickler at 0x10999c8c0>, (array([  3.00827754e-32,   2.97416794e+29,   1.34685259e+01, ...,\n         4.09872791e-18,   1.35751740e-12,   2.24696170e-03], dtype=float32),))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-be88c888eb19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/vmisra/Dropbox/lib/pylearn2/pylearn2/utils/serial.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(filepath, recurse_depth, retry)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;34m\" + Try using numpy.{save,load} (file with extension '.npy') \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;34m\"to save your file. It uses less memory when reading and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                 \"writing files than pickled files.\" % filepath)\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             improve_memory_error_message(e, \n",
      "\u001b[0;32m/Users/vmisra/Dropbox/lib/pylearn2/pylearn2/utils/mem.pyc\u001b[0m in \u001b[0;36mimprove_memory_error_message\u001b[0;34m(error, msg)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypicalMemoryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: ('Error allocating 368640 bytes of device memory (out of memory).', <function CudaNdarray_unpickler at 0x10999c8c0>, (array([  3.00827754e-32,   2.97416794e+29,   1.34685259e+01, ...,\n         4.09872791e-18,   1.35751740e-12,   2.24696170e-03], dtype=float32),))"
     ]
    }
   ],
   "source": [
    "models = OrderedDict()\n",
    "for model_folder in model_folders:\n",
    "    #load submodels\n",
    "    models = OrderedDict()\n",
    "    for submodel in submodels+[final_model]:\n",
    "        path = os.path.join(dir_model,model_folder,submodel)\n",
    "        if os.path.exists(path):\n",
    "            models[model_folder][submodel] = serial.load(path)\n",
    "    \n",
    "    #define graph inputs/outputs\n",
    "    Xs = OrderedDict()\n",
    "    Ys = OrderedDict()\n",
    "    for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xs = OrderedDict()\n",
    "Ys = OrderedDict()\n",
    "for model_folder in models:\n",
    "    Xs[model_folder]=OrderedDict()\n",
    "    Ys[model_folder]=OrderedDict()\n",
    "    for (idx,submodel) in enumerate(models[model_folder].keys()[:-1]):\n",
    "#    for (idx,submodel) in enumerate(models[model_folder].keys()): #replaces the above for no final_model\n",
    "        Xs[model_folder][submodel] = models[model_folder][submodel].get_input_space().make_theano_batch()\n",
    "        Y=Xs[model_folder][submodel]\n",
    "        for jdx in range(idx+1):\n",
    "            Y = models[model_folder][submodels[jdx]].encode(Y)\n",
    "        for jdx in range(idx+1)[::-1]:\n",
    "            Y = models[model_folder][submodels[jdx]].decode(Y)\n",
    "        Ys[model_folder][submodel] = Y\n",
    "    Xs[model_folder][final_model] = models[model_folder][final_model].get_input_space().make_theano_batch()\n",
    "    Ys[model_folder][final_model] = models[model_folder][final_model].reconstruct(Xs[model_folder][final_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Compute output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xhat = OrderedDict()\n",
    "for model_folder in Ys:\n",
    "    xhat[model_folder] = OrderedDict()\n",
    "    for submodel in Ys[model_folder]:\n",
    "        Y = Ys[model_folder][submodel]\n",
    "        X = Xs[model_folder][submodel]\n",
    "        xhat[model_folder][submodel]= Y.eval({X:test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##visualize outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_img = Image.fromarray(tile_raster_images(X=test_data,\n",
    "                                                  img_shape=(28,28),\n",
    "                                                  tile_shape=(10,10),\n",
    "                                                  tile_spacing=(1,1)))\n",
    "original_img.save('delete_me.png')\n",
    "print 'original'\n",
    "I.display(I.Image('delete_me.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model_folders = ['B6','B10']\n",
    "for submodel in submodels:#['finetune.pkl']: \n",
    "    for model_folder in model_folders:\n",
    "        reconstructed = Image.fromarray(tile_raster_images(X=xhat[model_folder][submodel],\n",
    "                                                  img_shape=(28,28),\n",
    "                                                  tile_shape=(10,10),\n",
    "                                                  tile_spacing=(1,1)))\n",
    "        reconstructed.save('delete_me.png')\n",
    "        print model_folder, submodel\n",
    "        I.display(I.Image('delete_me.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "params = [pickle.load(open(os.path.join(dir_model,model_folder,'params.pkl'),'r')) for model_folder in model_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
